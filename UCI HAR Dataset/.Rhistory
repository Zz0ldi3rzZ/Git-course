^([a-z]+) +\1 +[a-z]+ [0-9]
([a-z]+) +\1 +[a-z]+ [0-9]
q()
find packages("devtools")
find package("devtools")
find.package("devtools")
find.package()
install.packages("devtools")
find.page("devtools")
find.package("devtools")
install.packages("swirl")
library("swirl")
swirl()
5+7
x<5+7
x<-5+7
x
y<-x-3
y
z<-c(1.1,9,3.14)
c?
c()?
?c
?c
z c
zc
z c()
z c()
z y
z x
z
c(z,555)
c(z,555,z)
z*2+100
my_sqrt<-sqrt(z-1)
my_sqrt
my_div<-z/my_sqrt
my_div
a<-c(1,2,3,4)
c(1,2,3,4)+c(0,10)
c(1,2,3,4)+c(0,10,100)
z*2+1000
my_div
1:20
pi:10
15:1
`:`
":"
?`:`
seq(1,20)
seq(0,10,by=0.5)
my_seq(5,10,length=30)
my_seq<-(5,10,length=30)
my_seq<-seq(5,10,length=30)
length(my_seq)
1:length(my_seq)
seq(along=my_seq)
seq_along(my_seq)
req(0,times=40)
rep(0,times=40)
rep(c(0,1,2),times=10)
rep(c(0,1,2),each=10)
num_vect<-c(0.5,55,-10,6)
tf<-(num_vect<1)
tf<-num_vect<1
tf
num_vect>=6
my_char(c("My","name","is"))
my_char<-(c("My","name","is"))
my_char<-c("My","name","is")
my_char
paste(my_char, collapse=" ")
my_name<-c(my_char,"yueming")
my_name
past(my_name, collapse=" ")
paste(my_name, collapse=" ")
paste("Hello","world!",sep=" ")
paste(c("x","y","z"),1:3,collapse="")
paste(1:3,c("x","y","z"),collapse="")
paste(1:3,c("x","y","z"),sep="")
paste(1:3,c("X","Y","Z"),sep="")
paste(LETTERS,1:4,sep="_")
paste(LETTERS,1:4,sep="-")
x<-c(44,NA,5,NA)
x*3
y<-rnorm(1000)
z<-rep(NA,1000)
my_data<-sample(c(y,z),100)
my_na<-is.na(my_data)
my_na
my_data=NA
my_data==NA
sum(my_na)
my_data
0/0
inf/inf
Inf/Inf
Inf-Inf
x
x[1:10]
x[is.na(x)]
y<-x[!is.na(x)]
y
y[y>0]
x[x>0]
x[!is.na(x)&x>0]
c(x[3],x[5],x[7])
a[c(3,5,7)]
info()
a<-c(3,5,7)
a<-c[(3,5,7)]
a<-c(3, 5, 7)
skip()
x[0]
x[3000]
x[c(-2,-10)]
x[-c(2,10)]
vect<-c(foo=11,bar=2,norf=NA)
vect
names(foo)
names(vect)
vect2<-c(11,2,NA)
names(vects)<-c("foo","bar","norf")
names(vect2)<-c("foo","bar","norf")
identical(vect,vect2)
vect["bar"]
vect[c("foo","bar")]
my_vector<-c(1:20)
my_vector<-1:20
my_vector
dim(my_vector)
length(my_vector)
dim(my_vector)<-c(4,5)
dim(my_vector)
attributes(my_vector)
my_vector
class(my_vector)
my_matrix<my_vector
my_matrix<-my_vector
?matrix()
?matrix
my_matrix2<-matrix(1:20,nrow=4,ncol=5)
identical(my_matrix,my_matrix2)
patient<-c("Bill","Gina","Kelly","Sean")
patients<-c("Bill","Gina","Kelly","Sean")
cbine(patients,my_matrix)
cbind(patients,my_matrix)
my_data<-data.frame(patients,my_matrix)
my_data
class(my_data)
cnames<-c("patient","age","weight","bp","rating","test")
colnames(cnames)
colnames(my_data)<-cnames
my_data
library("swirl")
swirl()
library(swirl)
install_from_swirl("Data Analysis")
swirl()
add2<-function(x,y){
x+y
}
above<-function(x,n){
use<-x>n
x[use]
}
above(3,6)
above(12,10)
colunmnmean<-function(y,removeNA=TRUE){
nc<-ncol(y)
means<-numeric(nc)
for(i in 1:nc){
means[i]<-mean(y[,i],na.rm=removeNA)
}
means
}
colunmnmean(airquality)
install.packages("swirl")
library("swirl")
swirl()
install.packages("swirl")
install.packages("swirl")
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
swirl()
?read.csv
read.csv(path2csv,stringsAsFactors = FALSE)
mydf=read.csv(path2csv, stringsAsFactors = FALSE)
mydf = read.csv(path2csv, stringsAsFactors = FALSE)
info()
skip()
bye()
swirl()
main()
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran<-tbl_df(mydf)
rm("mydf")
cran(tbl_df)
?tbl_df
cran
?manip
select(cran, ip_id,
| package, country)
select(cran, ip_id,package, country)
mian()
main()
5:20
select(cran, r_arch:country)
select(cran,country:r_arch)
cran
select(cran, -time)
select(-x:-size)
select(-X:-size)
-5:20
-(5:20)
select-(x:size)
select(-(x:size))
select(cran, -(x:size))
select(cran, -(X:size))
filter(cran, package == "swirl")
filter(cran, r_version ==
| "3.1.1", country == "US")
filter(cran, r_version =="3.1.1", country == "US")
?Comparison (that's an uppercase C)
?comparison(that's an uppercase c')
comparison(that's an uppercase C)
?comparison (that's an uppercase C)
?comparison (that's an uppercase C)
?Comparison
filter(cran, r_version =="3.0.2", country == "IN")
filter(cran, r_version <="3.0.2", country == "IN")
filter(cran, country == "US" | country
| == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500 | r_os == "linux-gnu")
filter(cran, size > 100500 , r_os == "linux-gnu")
is.na(c(3,5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, r_version !=is.na())
filter(cran, r_version !is.na())
filter(cran, r_version =!is.na())
filter(cran, r_version =!is.na(1))
filter(cran, !is.na(r_version))
cran2<-select(cran,size:ip_id)
arrange(cran2, ip_id)
desc(ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package,ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3(cran,ip_id,package,size)
cran3<-(cran,ip_id,package,size)
cran3<-select(cran,ip_id,package,size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20，zise_gb=size_mb/2^10)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
cran3
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
library(Matrix)
links <- list(c(2,3,4,5,7),c(1),c(1,2),c(2,3,5),c(1,3,4,6),c(1,5),c(5))  ## 网页链接关系
toMatrix.links <- function(links) {
nodes <- 1:length(links)
res <- Matrix(0,nrow=length(nodes),ncol=length(nodes),sparse=TRUE)
idx <- unlist(links)+rep((1:length(nodes))-1,times=sapply(links,length))*length(nodes)
res[idx] <- 1
res <- t(t(res)/colSums(res))
return(res)
}
pageRank.naive <- function(links) {
trans.Matrix <- toMatrix.connection(links)
res <- eigen(trans.Matrix)
return(list(val=res$values[1],vec=res$vectors[,1]))
}
pageRank.naive(links)
？toMatrix.connection
version
install.packages(c("dplyr", "httpuv", "httr", "jsonlite"))
jsonData <- fromJSON(req$url)
library(rjson)
setwd("G:/Data Science Speciality Track/Getting and Cleaning Data/Cousera-Getting-and-Cleaning-Data/Project")
url="https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(url,destfile="./data")
setwd("G:/Data Science Speciality Track/Getting and Cleaning Data/Cousera-Getting-and-Cleaning-Data/Project/UCI HAR Dataset")
#Project Script
#Set directory path
setwd("G:/Data Science Speciality Track/Getting and Cleaning Data/Cousera-Getting-and-Cleaning-Data/Project/UCI HAR Dataset")
#Requirement 1:  Merges the training and the test sets to create one data set.
#Read the activity files
url="https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(url,destfile="./UCI HAR Dataset")
trainLabel <- read.table("./train/y_train.txt")
table(trainLabel)
testLabel <- read.table("./test/y_test.txt")
table(testLabel)
#Read the data files.
trainData <- read.table("./train/X_train.txt")
dim(trainData) # 7352*561
head(trainData)
testData <- read.table("./test/X_test.txt")
dim(testData) # 2947*561
#Read the subject files.
trainSubject <- read.table("./train/subject_train.txt")
testSubject <- read.table("./test/subject_test.txt")
#Merge the training and the test sets
#Concatenate the data tables.
joinData <- rbind(trainData, testData)
dim(joinData) # 10299*561
joinLabel <- rbind(trainLabel, testLabel)
dim(joinLabel) # 10299*1
joinSubject <- rbind(trainSubject, testSubject)
dim(joinSubject) # 10299*1
#Requirement 2:Extracts only the measurements on the mean and standard
# deviation for each measurement.
features <- read.table("./features.txt")
dim(features)  # 561*2
meanStdIndices <- grep("mean\\(\\)|std\\(\\)", features[, 2])
length(meanStdIndices) # 66
joinData <- joinData[, meanStdIndices]
dim(joinData) # 10299*66
names(joinData) <- gsub("\\(\\)", "", features[meanStdIndices, 2]) # remove "()"
names(joinData) <- gsub("mean", "Mean", names(joinData)) # capitalize M
names(joinData) <- gsub("std", "Std", names(joinData)) # capitalize S
names(joinData) <- gsub("-", "", names(joinData)) # remove "-" in column names
#Requirement 3: Uses descriptive activity names to name the activities in the data set
activity <- read.table("./activity_labels.txt")
activity[, 2] <- tolower(gsub("_", "", activity[, 2]))#gsub:replace function
substr(activity[2, 2], 8, 8) <- toupper(substr(activity[2, 2], 8, 8))
substr(activity[3, 2], 8, 8) <- toupper(substr(activity[3, 2], 8, 8))
activityLabel <- activity[joinLabel[, 1], 2]
joinLabel[, 1] <- activityLabel
names(joinLabel) <- "activity"
#Requirement 4: Appropriately labels the data set with descriptive activity names.
names(joinSubject) <- "subject"
cleanedData <- cbind(joinSubject, joinLabel, joinData)
dim(cleanedData) # 10299*68
write.table(cleanedData, "merged_data.txt") # write out the 1st dataset
#Requirement 5: Creates a second, independent tidy data set with the average of each variable for each activity and each subject.
subjectLen <- length(table(joinSubject)) # 30
activityLen <- dim(activity)[1] # 6
columnLen <- dim(cleanedData)[2]
result <- matrix(NA, nrow=subjectLen*activityLen, ncol=columnLen)
result <- as.data.frame(result)
colnames(result) <- colnames(cleanedData)
row <- 1
for(i in 1:subjectLen) {
for(j in 1:activityLen) {
result[row, 1] <- sort(unique(joinSubject)[, 1])[i]
result[row, 2] <- activity[j, 2]
bool1 <- i == cleanedData$subject
bool2 <- activity[j, 2] == cleanedData$activity
result[row, 3:columnLen] <- colMeans(cleanedData[bool1&bool2, 3:columnLen])
row <- row + 1
}
}
head(result)
write.table(result, "data_with_means.txt") # write out the 2nd dataset
#data <- read.table("./data_with_means.txt")
#data[1:12, 1:3]
